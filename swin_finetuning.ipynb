{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8574d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision.models import swin_t, Swin_T_Weights\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55337277",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# PATHS\n",
    "PATH_TO_DATASET = './KeyPointsDataset'\n",
    "\n",
    "# IMAGES\n",
    "IMAGE_WIDTH  = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "# TRAINING\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SIZE  = 64\n",
    "NUM_EPOCH   = 20\n",
    "BASE_LR     = 3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04340883",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce0dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyPointsDataset(data.Dataset):\n",
    "    def __init__(self, path, type, transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.path = path\n",
    "        self.type = type\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.targets = []\n",
    "        self.csv = pd.read_csv(os.path.join(self.path, type, type + '_frames_keypoints.csv'))\n",
    "        self.len = self.csv.shape[0]\n",
    "\n",
    "        for i in range(self.len):\n",
    "            img_name = self.csv.iloc[i]['img_name']\n",
    "            targets = self.csv.iloc[i].drop('img_name').to_list()\n",
    "\n",
    "            self.files.append(img_name)\n",
    "            self.targets.append(targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.files[index]\n",
    "        targets = self.targets[index]\n",
    "\n",
    "        img = Image.open(os.path.join(self.path, self.type, 'images', image))\n",
    "        target = []\n",
    "\n",
    "        if (self.transform):\n",
    "            target = [t * (IMAGE_WIDTH / img.size[0]) for t in targets[:10]]\n",
    "            target.extend([t * (IMAGE_HEIGHT / img.size[1]) for t in targets[10:]])\n",
    "            img = self.transform(img)\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfed88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Resize((IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=tfs.InterpolationMode.BICUBIC),\n",
    "    tfs.ToDtype(torch.float32),\n",
    "    tfs.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c2d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeyPointsDataset(PATH_TO_DATASET, 'train', transforms)\n",
    "test_dataset = KeyPointsDataset(PATH_TO_DATASET, 'test', transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422409c",
   "metadata": {},
   "source": [
    "### Model changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd5d0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)\n",
    "model.head = nn.Linear(768, NUM_CLASSES)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.features[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398e63c",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed6c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, save=None):\n",
    "    opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), BASE_LR)\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    test_loss = 0\n",
    "    model.train()\n",
    "    for _e in range(NUM_EPOCH):\n",
    "        # ----- training -----\n",
    "        for x_batch, y_batch in tqdm(train_data, desc=f'Epoch {_e + 1}/{NUM_EPOCH}, test loss: {test_loss}', leave=False):\n",
    "            x_batch, y_batch = x_batch.to(device).float(), y_batch.to(device).float()\n",
    "\n",
    "            # gradient descent\n",
    "            opt.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = loss_func(output, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        test_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_test, y_test in test_data:\n",
    "                x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "\n",
    "                # get classification\n",
    "                output = model(x_test)\n",
    "                test_loss += F.mse_loss(y_test, output)\n",
    "\n",
    "    # ----- saving -----\n",
    "    if (save):\n",
    "        torch.save(model.state_dict(), 'models/' + save + '.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_dataloader, test_dataloader, 'ft_swin_t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
